{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Microloan Transaction Data Analysis\n",
        "\n",
        "> **Purpose:** Complete Question 2: simulate / load a large microloan transaction dataset (500 features, millions of rows), apply feature selection (top-10 by correlation with `default`), apply PCA to compress to a few components, compare model performance and speed, and produce a reflection report. This notebook is organized into *runnable cells* with explanatory text. There are placeholder cells where you should paste or describe your observed results after you run each step in Colab.\n"
      ],
      "metadata": {
        "id": "4HOuVTNCm4cN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Group Members**\n",
        "\n",
        "| Registration Number | Name             |\n",
        "|---------------------|------------------|\n",
        "| ST62/80168/2024     | GABRIEL NDUNDA   |\n",
        "| ST62/80313/2024     | DONSY OMBURA     |\n",
        "| ST62/80195/2024     | LEONARD KITI     |\n",
        "| ST62/80774/2024     | JOSEPHAT MOTONU  |\n",
        "| ST62/80472/2024     | TABITHA KIARIE   |\n"
      ],
      "metadata": {
        "id": "iGEcmmRgu8yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Notebook overview\n",
        "\n",
        "This Colab notebook contains the following sections (each as a separate cell):\n",
        "\n",
        "1. Environment setup (pip installs)\n",
        "2. Imports and utility functions\n",
        "3. Data generation (scalable, chunked) — or load your own CSV from Drive\n",
        "4. Quick sanity checks (head, distributions, default rate)\n",
        "5. Feature selection (top-10 by absolute Pearson correlation)\n",
        "6. Dimensionality reduction (PCA / IncrementalPCA)\n",
        "7. Modeling comparison (Logistic Regression on: full numeric features, top-10, PCA) with timing and ROC AUC\n",
        "8. Export reduced dataset to CSV (for Google Drive)\n",
        "9. Reflection/report template (placeholders for you to fill with experiment results)\n"
      ],
      "metadata": {
        "id": "TePZvD2Dnk1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Environment setup"
      ],
      "metadata": {
        "id": "P01r8YocoGHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQCX1gujmejc"
      },
      "outputs": [],
      "source": [
        "# Run this cell first in Colab to install required packages\n",
        "!pip install --quiet pandas numpy scikit-learn scipy matplotlib seaborn tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Imports and helper utilities"
      ],
      "metadata": {
        "id": "71cAP23roVtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import expit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# utility: print memory info (optional)\n",
        "try:\n",
        "    import psutil\n",
        "    def show_mem():\n",
        "        p = psutil.Process()\n",
        "        print(f\"RSS: {p.memory_info().rss / 1024**2:.1f} MB\")\n",
        "except Exception:\n",
        "    def show_mem():\n",
        "        pass\n",
        "\n",
        "print(\"imports ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjhYSq7-m4AK",
        "outputId": "7b31e11d-ff2b-4a04-80cd-7a82c6ba9ad8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imports ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data generation (scalable, chunked)\n",
        "\n",
        "> This cell creates a gzipped CSV in chunks so you can generate millions of rows without exhausting RAM. Adjust `TOTAL_ROWS` and `CHUNK_SIZE` depending on your Colab runtime memory."
      ],
      "metadata": {
        "id": "vGsFzom7ox8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PARAMETERS — change these as needed\n",
        "TOTAL_ROWS = 200_000   # change to 1_000_000 or more if you want (Colab free RAM limits apply)\n",
        "CHUNK_SIZE = 50_000\n",
        "N_FEATURES = 500\n",
        "OUTFILE = \"/content/microloans_generated.csv.gz\"\n",
        "SEED = 42\n",
        "\n",
        "# generator function (same as in the proper generator script)\n",
        "from numpy.random import default_rng\n",
        "\n",
        "def generate_chunk_df(start_id, n_rows, n_features=N_FEATURES, seed=SEED):\n",
        "    rng = default_rng(seed + start_id)\n",
        "    X = rng.normal(0, 1, size=(n_rows, n_features)).astype(\"float32\")\n",
        "    causal_idx = np.arange(12)\n",
        "    weights = rng.normal(0.8, 0.5, size=len(causal_idx))\n",
        "    linear = X[:, causal_idx] @ weights\n",
        "    month = rng.integers(1, 13, size=n_rows)\n",
        "    seasonal = np.sin(month / 12 * 2 * np.pi)\n",
        "    score = linear + seasonal + rng.normal(0, 1, size=n_rows)\n",
        "    prob_default = expit((score - score.mean()) / (score.std() + 1e-9)) * 0.5\n",
        "    default = (rng.random(n_rows) < prob_default).astype(int)\n",
        "    cols = [f\"feat_{i:03d}\" for i in range(n_features)]\n",
        "    df = pd.DataFrame(X, columns=cols)\n",
        "    df[\"month\"] = month\n",
        "    df[\"client_id\"] = np.arange(start_id, start_id + n_rows)\n",
        "    df[\"default\"] = default\n",
        "    return df\n",
        "\n",
        "# Write in chunks\n",
        "if os.path.exists(OUTFILE):\n",
        "    os.remove(OUTFILE)\n",
        "\n",
        "wrote_header = False\n",
        "current_start = 1\n",
        "rows_written = 0\n",
        "for start in range(0, TOTAL_ROWS, CHUNK_SIZE):\n",
        "    nrows = min(CHUNK_SIZE, TOTAL_ROWS - start)\n",
        "    df_chunk = generate_chunk_df(current_start, nrows)\n",
        "    df_chunk.to_csv(OUTFILE, index=False, header=not wrote_header, compression=\"gzip\", mode=\"a\")\n",
        "    wrote_header = True\n",
        "    current_start += nrows\n",
        "    rows_written += nrows\n",
        "    print(f\"Wrote {rows_written}/{TOTAL_ROWS} rows\")\n",
        "    del df_chunk\n",
        "    gc.collect()\n",
        "\n",
        "print(\"Data generation finished. File:\", OUTFILE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hB_Mxn4dorxJ",
        "outputId": "9466aa7a-d43b-4d58-83f7-336b1045f099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 50000/200000 rows\n",
            "Wrote 100000/200000 rows\n",
            "Wrote 150000/200000 rows\n",
            "Wrote 200000/200000 rows\n",
            "Data generation finished. File: /content/microloans_generated.csv.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Load dataset\n",
        "\n",
        "> Load the generated gzipped CSV. For very large files you can use `pd.read_csv(..., chunksize=...)` to iterate."
      ],
      "metadata": {
        "id": "GrDKn5b8pRNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust path if using your own file from Drive\n",
        "DATAFILE = \"/content/microloans_generated.csv.gz\"\n",
        "\n",
        "# quick load (if dataset fits in memory)\n",
        "df = pd.read_csv(DATAFILE, compression=\"gzip\")\n",
        "print(df.shape)\n",
        "df.head()\n",
        "\n",
        "# If memory is tight, consider reading only numeric columns or using dtype=float32 for numeric."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "yNCpFsnDpJVl",
        "outputId": "f27f9f4f-a9ba-41d8-d632-1a5c0f28d3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200000, 503)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   feat_000  feat_001  feat_002  feat_003  feat_004  feat_005  feat_006  \\\n",
              "0  0.244230  0.678178 -0.585529 -0.908673 -1.991838  0.971623  0.016657   \n",
              "1  0.553531  0.846116  1.803438  0.175773  0.469270  0.181753 -1.612282   \n",
              "2  0.604609  1.223441 -0.007221 -0.090196 -1.057149 -0.366855 -0.661511   \n",
              "3 -0.358611 -0.538976 -0.232811 -0.977738  0.233612  0.412751  0.255036   \n",
              "4  0.259756 -0.910076 -0.280531  0.359888  1.213674 -0.904145  0.212028   \n",
              "\n",
              "   feat_007  feat_008  feat_009  ...  feat_493  feat_494  feat_495  feat_496  \\\n",
              "0  0.205731 -0.783595  1.226498  ...  0.733248 -0.937926 -0.249340 -0.453826   \n",
              "1 -1.058011  0.470706 -0.437141  ... -0.640014 -0.325898  0.569612  0.143844   \n",
              "2  0.999835 -0.260388 -0.284669  ...  1.407685  0.656622 -0.698291 -1.473563   \n",
              "3  0.121842  1.297138 -0.276421  ...  0.383200 -0.752495  1.884973  1.577014   \n",
              "4 -1.409418  0.816652  0.495194  ... -0.310847  0.416164  1.364584 -0.737344   \n",
              "\n",
              "   feat_497  feat_498  feat_499  month  client_id  default  \n",
              "0 -0.505037 -0.618948  0.593156     10          1        1  \n",
              "1 -0.104949  0.839310 -0.741194     12          2        1  \n",
              "2  0.255281  0.461254 -0.231639      3          3        0  \n",
              "3 -0.781976  1.250490  0.595441      9          4        0  \n",
              "4 -0.247227 -0.548786 -1.391601      7          5        0  \n",
              "\n",
              "[5 rows x 503 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97a7596a-a597-48a3-9651-22cdb706f214\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feat_000</th>\n",
              "      <th>feat_001</th>\n",
              "      <th>feat_002</th>\n",
              "      <th>feat_003</th>\n",
              "      <th>feat_004</th>\n",
              "      <th>feat_005</th>\n",
              "      <th>feat_006</th>\n",
              "      <th>feat_007</th>\n",
              "      <th>feat_008</th>\n",
              "      <th>feat_009</th>\n",
              "      <th>...</th>\n",
              "      <th>feat_493</th>\n",
              "      <th>feat_494</th>\n",
              "      <th>feat_495</th>\n",
              "      <th>feat_496</th>\n",
              "      <th>feat_497</th>\n",
              "      <th>feat_498</th>\n",
              "      <th>feat_499</th>\n",
              "      <th>month</th>\n",
              "      <th>client_id</th>\n",
              "      <th>default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.244230</td>\n",
              "      <td>0.678178</td>\n",
              "      <td>-0.585529</td>\n",
              "      <td>-0.908673</td>\n",
              "      <td>-1.991838</td>\n",
              "      <td>0.971623</td>\n",
              "      <td>0.016657</td>\n",
              "      <td>0.205731</td>\n",
              "      <td>-0.783595</td>\n",
              "      <td>1.226498</td>\n",
              "      <td>...</td>\n",
              "      <td>0.733248</td>\n",
              "      <td>-0.937926</td>\n",
              "      <td>-0.249340</td>\n",
              "      <td>-0.453826</td>\n",
              "      <td>-0.505037</td>\n",
              "      <td>-0.618948</td>\n",
              "      <td>0.593156</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.553531</td>\n",
              "      <td>0.846116</td>\n",
              "      <td>1.803438</td>\n",
              "      <td>0.175773</td>\n",
              "      <td>0.469270</td>\n",
              "      <td>0.181753</td>\n",
              "      <td>-1.612282</td>\n",
              "      <td>-1.058011</td>\n",
              "      <td>0.470706</td>\n",
              "      <td>-0.437141</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.640014</td>\n",
              "      <td>-0.325898</td>\n",
              "      <td>0.569612</td>\n",
              "      <td>0.143844</td>\n",
              "      <td>-0.104949</td>\n",
              "      <td>0.839310</td>\n",
              "      <td>-0.741194</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.604609</td>\n",
              "      <td>1.223441</td>\n",
              "      <td>-0.007221</td>\n",
              "      <td>-0.090196</td>\n",
              "      <td>-1.057149</td>\n",
              "      <td>-0.366855</td>\n",
              "      <td>-0.661511</td>\n",
              "      <td>0.999835</td>\n",
              "      <td>-0.260388</td>\n",
              "      <td>-0.284669</td>\n",
              "      <td>...</td>\n",
              "      <td>1.407685</td>\n",
              "      <td>0.656622</td>\n",
              "      <td>-0.698291</td>\n",
              "      <td>-1.473563</td>\n",
              "      <td>0.255281</td>\n",
              "      <td>0.461254</td>\n",
              "      <td>-0.231639</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.358611</td>\n",
              "      <td>-0.538976</td>\n",
              "      <td>-0.232811</td>\n",
              "      <td>-0.977738</td>\n",
              "      <td>0.233612</td>\n",
              "      <td>0.412751</td>\n",
              "      <td>0.255036</td>\n",
              "      <td>0.121842</td>\n",
              "      <td>1.297138</td>\n",
              "      <td>-0.276421</td>\n",
              "      <td>...</td>\n",
              "      <td>0.383200</td>\n",
              "      <td>-0.752495</td>\n",
              "      <td>1.884973</td>\n",
              "      <td>1.577014</td>\n",
              "      <td>-0.781976</td>\n",
              "      <td>1.250490</td>\n",
              "      <td>0.595441</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.259756</td>\n",
              "      <td>-0.910076</td>\n",
              "      <td>-0.280531</td>\n",
              "      <td>0.359888</td>\n",
              "      <td>1.213674</td>\n",
              "      <td>-0.904145</td>\n",
              "      <td>0.212028</td>\n",
              "      <td>-1.409418</td>\n",
              "      <td>0.816652</td>\n",
              "      <td>0.495194</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.310847</td>\n",
              "      <td>0.416164</td>\n",
              "      <td>1.364584</td>\n",
              "      <td>-0.737344</td>\n",
              "      <td>-0.247227</td>\n",
              "      <td>-0.548786</td>\n",
              "      <td>-1.391601</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 503 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97a7596a-a597-48a3-9651-22cdb706f214')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-97a7596a-a597-48a3-9651-22cdb706f214 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-97a7596a-a597-48a3-9651-22cdb706f214');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-eff8abfb-4e03-4d7e-91f8-c58f40a6ecc4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eff8abfb-4e03-4d7e-91f8-c58f40a6ecc4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-eff8abfb-4e03-4d7e-91f8-c58f40a6ecc4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 6. Sanity checks\n",
        "\n",
        "Explain briefly (in text cell) you'll check default rate, distribution of a few features, and missing values. Then run the code cell below."
      ],
      "metadata": {
        "id": "DMC-pD9jptaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity checks\n",
        "print(\"Default rate:\", df[\"default\"].mean())\n",
        "print(\"Client id unique:\", df[\"client_id\"].nunique())\n",
        "print(\"Feature sample stats:\")\n",
        "print(df[[\"feat_000\",\"feat_001\",\"feat_002\"]].describe().T)\n",
        "\n",
        "# Placeholder for you to paste results\n",
        "# === YOUR SANITY CHECK RESULTS ===\n",
        "# Paste observed default rate and any notes here:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBvBZihMpfDr",
        "outputId": "b795ce69-8ee3-455a-fc38-e92d6721eb32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default rate: 0.24974\n",
            "Client id unique: 200000\n",
            "Feature sample stats:\n",
            "             count      mean       std       min       25%       50%  \\\n",
            "feat_000  200000.0  0.002335  0.998270 -4.153395 -0.673174  0.001195   \n",
            "feat_001  200000.0  0.002915  1.001018 -4.351909 -0.672159  0.003735   \n",
            "feat_002  200000.0  0.000395  0.999618 -4.046616 -0.674700  0.002535   \n",
            "\n",
            "               75%       max  \n",
            "feat_000  0.676466  4.668834  \n",
            "feat_001  0.681573  5.269891  \n",
            "feat_002  0.674862  4.758881  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Feature selection — Top-10 by absolute Pearson correlation\n",
        "\n",
        "> We'll compute the point-biserial correlation (Pearson between continuous features and binary `default`) and pick the top 10 features by absolute value. For very large datasets, compute correlation in chunks or use streaming statistics.\n"
      ],
      "metadata": {
        "id": "9XSNpAEjqMIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare numeric feature list\n",
        "numeric_cols = [c for c in df.columns if c.startswith(\"feat_\")]\n",
        "print(f\"Number of numeric features: {len(numeric_cols)}\")\n",
        "\n",
        "# Compute correlation with target\n",
        "corrs = df[numeric_cols].corrwith(df['default']).abs().sort_values(ascending=False)\n",
        "top_k = 10\n",
        "top_features = corrs.head(top_k).index.tolist()\n",
        "print(\"Top-10 features by abs(Pearson) with default:\")\n",
        "print(corrs.head(top_k))\n",
        "\n",
        "# Save selection\n",
        "with open('/content/top10_features.txt','w') as f:\n",
        "    f.write('\\n'.join(top_features))\n",
        "\n",
        "# Placeholder to record your observed top-10 list\n",
        "# === YOUR TOP-10 FEATURES ===\n",
        "# Paste the top-10 features printed above and any notes here:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSmtokeIqD_x",
        "outputId": "632463a9-a46f-4d29-9700-2880e0c0e39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of numeric features: 500\n",
            "Top-10 features by abs(Pearson) with default:\n",
            "feat_008    0.094142\n",
            "feat_003    0.074154\n",
            "feat_000    0.072358\n",
            "feat_001    0.048889\n",
            "feat_011    0.046333\n",
            "feat_002    0.046184\n",
            "feat_006    0.044890\n",
            "feat_007    0.044120\n",
            "feat_005    0.039195\n",
            "feat_009    0.036185\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Dimensionality reduction — PCA (Code cell)\n",
        "\n",
        "> We'll standardize selected features and run PCA. If the dataset is very large, `IncrementalPCA` is used to fit in batches."
      ],
      "metadata": {
        "id": "oSkdX4SDrzfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA on top-10 and on a larger set if desired\n",
        "n_pca_components = 5\n",
        "\n",
        "# Standardize top-10\n",
        "X_top10 = df[top_features].values\n",
        "scaler_top10 = StandardScaler()\n",
        "X_top10_scaled = scaler_top10.fit_transform(X_top10)\n",
        "\n",
        "pca_top10 = PCA(n_components=n_pca_components, random_state=0)\n",
        "X_top10_pca = pca_top10.fit_transform(X_top10_scaled)\n",
        "print(\"Top-10 PCA explained variance ratio (cumulative):\", pca_top10.explained_variance_ratio_.cumsum())\n",
        "\n",
        "# PCA on many features using IncrementalPCA (memory-friendly)\n",
        "USE_INCR = True\n",
        "incr_components = 10\n",
        "if USE_INCR:\n",
        "    ipca = IncrementalPCA(n_components=incr_components)\n",
        "    chunksize = 50_000\n",
        "    for start in range(0, df.shape[0], chunksize):\n",
        "        end = min(start + chunksize, df.shape[0])\n",
        "        batch = df.iloc[start:end][numeric_cols].values\n",
        "        batch = batch.astype('float32')\n",
        "        # scale each batch (fit_transform would leak stats); here we center per-batch (approximate) or use a global StandardScaler in two passes\n",
        "        batch = (batch - batch.mean(axis=0)) / (batch.std(axis=0) + 1e-9)\n",
        "        ipca.partial_fit(batch)\n",
        "    # transform into components (do second pass)\n",
        "    X_ipca = []\n",
        "    for start in range(0, df.shape[0], chunksize):\n",
        "        end = min(start + chunksize, df.shape[0])\n",
        "        batch = df.iloc[start:end][numeric_cols].values\n",
        "        batch = batch.astype('float32')\n",
        "        batch = (batch - batch.mean(axis=0)) / (batch.std(axis=0) + 1e-9)\n",
        "        X_ipca.append(ipca.transform(batch))\n",
        "    X_ipca = np.vstack(X_ipca)\n",
        "    print(\"IncrementalPCA result shape:\", X_ipca.shape)\n",
        "\n",
        "# Placeholder to record PCA explained variance or observations\n",
        "# === YOUR PCA OBSERVATIONS ===\n",
        "# Paste explained variance or comments here:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soN3QhTSrskB",
        "outputId": "cd7656bc-4772-4e90-b63e-5c16a6df82d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-10 PCA explained variance ratio (cumulative): [0.10100549 0.20166813 0.30230078 0.40261951 0.50280859]\n",
            "IncrementalPCA result shape: (200000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Modeling comparison: Full vs Top-10 vs PCA\n",
        "\n",
        "> We'll train a logistic regression on three datasets and record training time and ROC AUC on a holdout set. For big datasets you may want to sample for training.\n"
      ],
      "metadata": {
        "id": "yj7F_G3RrU0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for comparison\n",
        "TARGET = 'default'\n",
        "SAMPLE_FOR_TRAINING = False  # set True if dataset is huge and you prefer to sample\n",
        "SAMPLE_FRAC = 0.2\n",
        "\n",
        "if SAMPLE_FOR_TRAINING:\n",
        "    df_model = df.sample(frac=SAMPLE_FRAC, random_state=42)\n",
        "else:\n",
        "    df_model = df.copy()\n",
        "\n",
        "X_full = df_model[numeric_cols].values\n",
        "X_top10 = df_model[top_features].values\n",
        "X_pca_top10 = X_top10_pca if X_top10_pca.shape[0] == df_model.shape[0] else None\n",
        "\n",
        "y = df_model[TARGET].values\n",
        "\n",
        "def train_and_eval(X, y, label):\n",
        "    t0 = time.time()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    model = LogisticRegression(max_iter=200, solver='saga')\n",
        "    model.fit(X_train, y_train)\n",
        "    y_prob = model.predict_proba(X_test)[:,1]\n",
        "    auc = roc_auc_score(y_test, y_prob)\n",
        "    t1 = time.time()\n",
        "    return dict(label=label, time_s=t1-t0, auc=auc, n_features=X.shape[1])\n",
        "\n",
        "results = []\n",
        "\n",
        "# Full (may be slow)\n",
        "print(\"Training Full model — this may take time\")\n",
        "res_full = train_and_eval(X_full, y, 'Full')\n",
        "print(res_full)\n",
        "results.append(res_full)\n",
        "\n",
        "# Top-10\n",
        "print(\"Training Top-10 model\")\n",
        "res_top10 = train_and_eval(X_top10, y, 'Top-10')\n",
        "print(res_top10)\n",
        "results.append(res_top10)\n",
        "\n",
        "# PCA on top-10 (if available)\n",
        "if X_pca_top10 is not None:\n",
        "    print(\"Training PCA (top-10) model\")\n",
        "    res_pca = train_and_eval(X_pca_top10, y, f'PCA_top10_{X_pca_top10.shape[1]}')\n",
        "    print(res_pca)\n",
        "    results.append(res_pca)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Save results for your reflection\n",
        "results_df.to_csv('/content/model_comparison_results.csv', index=False)\n",
        "\n",
        "# === YOUR MODELING RESULTS ===\n",
        "# Paste the printed results (training times, AUCs) here and any observations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPFSjvJjrE_J",
        "outputId": "76a9952e-a966-4594-8c3e-b4c61b5b69ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Full model — this may take time\n",
            "{'label': 'Full', 'time_s': 41.60721015930176, 'auc': np.float64(0.6248187074111766), 'n_features': 500}\n",
            "Training Top-10 model\n",
            "{'label': 'Top-10', 'time_s': 2.5789544582366943, 'auc': np.float64(0.6245846913224454), 'n_features': 10}\n",
            "Training PCA (top-10) model\n",
            "{'label': 'PCA_top10_5', 'time_s': 1.642754316329956, 'auc': np.float64(0.5826454378403728), 'n_features': 5}\n",
            "         label     time_s       auc  n_features\n",
            "0         Full  41.607210  0.624819         500\n",
            "1       Top-10   2.578954  0.624585          10\n",
            "2  PCA_top10_5   1.642754  0.582645           5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# **Step 10: Final Reflection Report (Using Your Actual Outputs)**\n",
        "\n",
        "**Microloan Transaction Data Analysis — Question 2 (20 Marks)**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Summary of Dataset**\n",
        "\n",
        "* **Total rows analyzed:** 200,000  \n",
        "* **Total numeric features before reduction:** 500  \n",
        "* **Target variable:** `default`\n",
        "\n",
        "The dataset is high-dimensional (500 variables) with millions of records possible, representing monthly microloan transaction logs for Kenyan borrowers.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Feature Selection (Top-10 Correlated Features)**\n",
        "\n",
        "Using absolute Pearson correlations between each numeric feature and the target `default`, the **top-10 selected features** were:\n",
        "\n",
        "| Rank | Feature    | Correlation |\n",
        "| ---- | ---------- | ----------- |\n",
        "| 1    | `feat_008` | 0.094142    |\n",
        "| 2    | `feat_003` | 0.074154    |\n",
        "| 3    | `feat_000` | 0.072358    |\n",
        "| 4    | `feat_001` | 0.048889    |\n",
        "| 5    | `feat_011` | 0.046333    |\n",
        "| 6    | `feat_002` | 0.046184    |\n",
        "| 7    | `feat_006` | 0.044890    |\n",
        "| 8    | `feat_007` | 0.044120    |\n",
        "| 9    | `feat_005` | 0.039195    |\n",
        "| 10   | `feat_009` | 0.036185    |\n",
        "\n",
        "### **Reflection**\n",
        "* The strongest correlation (0.094) is modest, which is expected in noisy, high-dimensional financial datasets.  \n",
        "* The fact that most of the top features are among the first 12 (\"causal features\") confirms the dataset was generated correctly.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. PCA Dimensionality Reduction Results**\n",
        "\n",
        "### **PCA on the Top-10 Features**\n",
        "\n",
        "Cumulative explained variance over 5 components:\n",
        "\n",
        "[0.1010, 0.2017, 0.3023, 0.4026, 0.5028]\n",
        "\n",
        "\n",
        "### **Interpretation**\n",
        "* The first 5 principal components capture **~50.3%** of variance in the top-10 features.  \n",
        "* Because the dataset is noisy and the default signal is weak, PCA spreads variance relatively evenly across components.  \n",
        "* PCA reduces the feature space from 10 → 5 but does so at the cost of **interpretability**.\n",
        "\n",
        "### **Incremental PCA Output**\n",
        "\n",
        "Shape: (200000, 10)\n",
        "\n",
        "\n",
        "This means the full dataset was successfully compressed into 10 components using a memory-efficient method.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. Model Performance Comparison**\n",
        "\n",
        "| Model                        | Time (s)    | AUC         | # Features |\n",
        "| ---------------------------- | ----------- | ----------- | ---------- |\n",
        "| **Full (500 features)**      | **41.61 s** | **0.62482** | 500        |\n",
        "| **Top-10 Selected Features** | **2.58 s**  | **0.62458** | 10         |\n",
        "| **PCA (5 components)**       | **1.64 s**  | **0.58265** | 5          |\n",
        "\n",
        "### **Key Observations**\n",
        "* **Full model** performs best but is extremely slow (over 41 seconds).  \n",
        "* **Top-10 model** performs almost identically in accuracy while being **16× faster** to train.  \n",
        "* **PCA model** is fastest but loses significant accuracy due to loss of interpretability and signal dilution.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Final Reflection (Required for Marks)**\n",
        "\n",
        "### **A. Impact on Dataset Size**\n",
        "* **Original:** 500 features  \n",
        "* **After feature selection:** 10 features (98% reduction)  \n",
        "* **After PCA:** 5 principal components  \n",
        "\n",
        "Results show a dramatic reduction in storage and memory footprint.\n",
        "\n",
        "---\n",
        "\n",
        "### **B. Impact on Speed**\n",
        "* Training time improved from **41.6s → 2.6s** using feature selection (**16× faster**).  \n",
        "* PCA further reduced time to **1.6s**, making it **~26× faster** than the full model.\n",
        "\n",
        "---\n",
        "\n",
        "### **C. Impact on Model Accuracy**\n",
        "* **Full model AUC:** 0.62482  \n",
        "* **Top-10 AUC:** 0.62458 (almost identical)  \n",
        "* **PCA model AUC:** 0.58265 (noticeable drop due to abstraction of features)\n",
        "\n",
        "Feature selection preserves accuracy while greatly improving speed.  \n",
        "PCA trades accuracy for speed and compression.\n",
        "\n",
        "---\n",
        "\n",
        "### **D. Overall Conclusions**\n",
        "\n",
        "1. **Feature selection is the most effective technique** for this microloan dataset because it:  \n",
        "   * Improves model speed  \n",
        "   * Maintains predictive accuracy  \n",
        "   * Preserves interpretability  \n",
        "\n",
        "2. **PCA is useful for compression**, but not ideal when prediction accuracy is the priority.\n",
        "\n",
        "3. For real microloan providers managing millions of records, feature selection helps:  \n",
        "   * Reduce compute cost  \n",
        "   * Speed up model retraining  \n",
        "   * Improve deployment efficiency  \n",
        "\n",
        "4. PCA may still be preferred when:  \n",
        "   * Visualizing patterns  \n",
        "   * Reducing storage for downstream tasks  \n",
        "   * Working in environments with strict memory limits  \n",
        "\n",
        "---\n",
        "\n",
        "## **6. Final Answer Summary (as required for the question)**\n",
        "\n",
        "> **I applied feature selection to identify the top 10 most correlated features with loan default, then applied PCA to reduce dimensionality further. Feature selection reduced dataset size and improved processing speed by 16× with no loss in model accuracy. PCA reduced dimension more aggressively but caused a decrease in predictive accuracy. Overall, feature selection was the most effective method for balancing accuracy, speed, and interpretability.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b9SyilmWtrZO"
      }
    }
  ]
}